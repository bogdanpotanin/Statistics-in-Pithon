# --------
# Потанин Богдан Станиславович
# Математическая Статистика в Python
# Урок 7. Метод моментов
# --------

import sys
import math
import pandas as pd
import numpy as np
import scipy
import matplotlib.pyplot as plt
import seaborn
from scipy.stats import t, chi2, f, norm, poisson, binom, uniform, multivariate_normal

np.set_printoptions(suppress = True)                    # уберем scientific notation

# --------
# Часть №1. Получение оценок методом моентов
# --------

# Сгенерируем выборку из равногомерного
# распределения
np.random.seed(123)                                     # для воспроизводимости результатов, полученных с использованием
                                                        # выборок, необходима установка случайного зерна
n = 1000
a = 2                                                   # параметры равномерного
b = 5                                                   # распределения
x = np.random.uniform(size = n,                         # объем выборки
                      low = a,                          # наименьшее значение
                      high = b)                         # наибольшее значение

# Найдем первый и второй начальные
# выборочные моменты
x_1 = np.mean(x)                                        # первый начальный выборочный момент
x_2 = np.mean(x ** 2)                                   # второй начальный выборочный момент

# Рассчитаем оценки параметров при
# помощи метода моментов
a_est = x_1 - np.sqrt(3 * (x_2 - x_1 ** 2))             # оценка параметра 'a'
b_est = x_1 + np.sqrt(3 * (x_2 - x_1 ** 2))             # оценка параметра 'b'

# --------
# Часть №2. Асимптотическое совместное распределение
#           выборочных моментов
# --------

# Обозначим i-й начальный выборочный момент как x_i.
# Рассмотрим совместное распределеине начальных
# выборочных моментов x_1,...,x_r. Оно будет
# многомерным нормальным, причем:
# E(x_i) = E(X1)
# Var(x_i) = Var(X1) / n
# Cov(x_i, x_j) = E(X1 ^ (i + j)) - E(X1 ^ i) * E(X1 ^ j)

# Найдем параметры асимптотического совместного распределения
# первого и второго начальных выборочных моментов. Их совместное
# распределение будет являться многомерным нормальным.
x_1_mean = (a + b) / 2                                  # математическое ожидание первого выборочного момента
x_2_mean = (b ** 3 - a ** 3) / (3 * (b - a))            # математическое ожидание второго выборочного момента
x_1_var = (x_2_mean - x_1_mean ** 2) / n                # дисперсия первого выборочного момента
x_2_var = ((b ** 5 - a ** 5) / (5 * (b - a))
           - x_2_mean ** 2) / n                         # дисперсия первого выборочного момента
x_12_cov = ((b ** 4 - a ** 4) / (4 * (b - a))
            - x_2_mean * x_1_mean) / n                  # ковариация первого и второго выборочных моментов
# Сохраним результат в форме векторов
x_mean = np.array([x_1_mean, x_2_mean])                 # вектор математических ожиданий выборочных моментов
x_cov = np.array([[x_1_var, x_12_cov],                  # ковариационная матрица выборочных моментов
                  [x_12_cov, x_2_var]])

# Убедимся, что параметры были найдены верно
np.random.seed(123)
m = 10000                                               # генерируем идентичные выборки
x_1_vec = np.empty(m)                                   # для каждой из которых будут рассчитаны первый и второй
x_2_vec = np.empty(m)                                   # начальные выборочные моменты
for i in range(0, m):
    x_new = np.random.uniform(size = n,
                              low = a, high = b)
    x_1_vec[i] = np.mean(x_new)
    x_2_vec[i] = np.mean(x_new ** 2)
# Сверяем результаты
    # Рассмотрим истинные параметры асимптотичекоского
    # распределения выборочных моментов и их оценки
x_mean                                                  # настоящее математическое ожидание
[np.mean(x_1_vec), np.mean(x_2_vec)]                    # оценка математического ожидания
x_cov                                                   # настоящая ковариационная матрица
np.cov(x_1_vec, x_2_vec)                                # оценка ковариационной матрицы
    # Рассчитаем P(x_1 <= 3.5, x_2 <= 13)
multivariate_normal.cdf(x = [3.5, 13],                  # используя истинное асимптотическое
                        mean = x_mean,                  # распределение моментов
                        cov = x_cov)
np.mean(((x_1_vec <= 3.5) & (x_2_vec <= 13)))           # приблизительно, применяя эмпирическую
                                                        # функцию распределения

# --------
# Часть №3. Асимптотическое распределение оценок
#           метода моментов
# --------

# Воспользуемся дельта методом для того, чтобы найти
# параметры асимптотического распределения оценки
# параметра 'b', которое будет нормальным
b_est_grad = np.array([1 - np.sqrt(3) * x_1_mean /                      # градиент оценки
                       np.sqrt(x_2_mean - x_1_mean ** 2),               # по моментам
                      np.sqrt(3 / 4) / np.sqrt(x_2_mean -
                                        x_1_mean ** 2)])
b_est_mean = b                                                          # асимптотическое математическое ожидание оценки 'b'
b_est_var = np.matmul(np.matmul(b_est_grad, x_cov), b_est_grad)         # асимптотическая дисперсия оценки 'b'
# Заменяя x_1_mean и x_2_mean на x_1 и x_2 соответственно
# можно было бы получить состоятельные оценки данных параметров

# Убедимся, что распределение действительно является нормальным
# с найденными параметрами, сравнив:
# 1) эмпирическую и теоретическую
#    функции распределения оценки параметра 'b'
a_est_vec = x_1_vec - np.sqrt(3 * (x_2_vec - x_1_vec ** 2))             # оценки параметра 'a'
b_est_vec = x_1_vec + np.sqrt(3 * (x_2_vec - x_1_vec ** 2))             # оценки параметра 'b'
a_est_vec = np.sort(a_est_vec)                                          # сортируем для удобства
b_est_vec = np.sort(b_est_vec)                                          # построения графиков
F_b_est = norm.cdf(b_est_vec,
                   loc = b_est_mean, scale = np.sqrt(b_est_var))        # теоретическая функция распределения оценки 'b'
plt.xlabel('x')                                                         # название нижней оси графика
plt.ylabel('F(x)')                                                      # название верхней оси графика
plt.plot(b_est_vec, F_b_est, '--', linewidth = 3,                       # график теоретической функции распределеиня оценки 'b'
  label = "CDF", color = "limegreen")
seaborn.ecdfplot(b_est_vec, stat = 'proportion',                        # график выборочной функции распределения
                 color = "palevioletred",
                 label = "ECDF",
                 linewidth = 2)
plt.legend()
# 2) Теоретическую функцию плотности и гистограмму
f_b_est = norm.pdf(b_est_vec,
                   loc = b_est_mean, scale = np.sqrt(b_est_var))        # теоретическая функция плотности оценки 'b'

plt.xlabel('x')                                                         # название нижней оси графика
plt.ylabel('f(x)')                                                      # название верхней оси графика
plt.plot(b_est_vec, f_b_est, '--', linewidth = 3,                       # график теоретической функции плотности оценки 'b'
  label = "PDF", color = "limegreen")
seaborn.histplot(b_est_vec, stat = 'density',                           # гистограмма
                 color = "palevioletred",
                 label = "histogram",
                 bins = 30)
plt.legend()

# Рассчитаем вероятность того, что оценка 'b' отклонится
# от истинного значения менее, чем на 1%:
norm.cdf(x = b * 1.01,loc = b_est_mean, scale = np.sqrt(b_est_var)) - \
norm.cdf(x = b * 0.99,loc = b_est_mean, scale = np.sqrt(b_est_var))

# Задания
# 1. Для выборки из 1000 наблюдений из экспоненциального
#    распределения с параметром 'lambda = 5' найдите оценку
#    данного параметра используя второй начальный момент,
#    после чего:
#    1)     Найдите параметры асимптотического
#           распределения данной оценки
#    2)     Рассчитайте вероятность того, что
#           оценка отклонится от истинного
#           значения более, чем на 1%.
#   3)      Визуализируйте соотношение гистограммы
#           и функции плотности оценки
# 2. Повторите предыдущее задание для выборки из биномиального
#    распределения с параметром 'p = 0.8'.
# 3. В представленном выше примере рассчитайте:
#    1*)    вероятность того, что оценка параметра 'b' превысит
#           оценку параметра 'a' более, чем в 2.4 раза.
#    2*)    вероятность того, что оценка параметра 'b' превысит
#           истинное значение более, чем на 1%, при условии, что
#           оценка параметра 'a' оказалась меньше истинного
#           значения на 0.5%.